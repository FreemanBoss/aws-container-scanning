"""
AWS Lambda Function: Vulnerability Aggregator
Aggregates vulnerability data across all scanned images and generates reports
"""

import json
import os
import logging
from datetime import datetime, timedelta
from decimal import Decimal
from collections import defaultdict
import boto3
from botocore.exceptions import ClientError

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# AWS clients
dynamodb = boto3.resource('dynamodb')
s3_client = boto3.client('s3')

# Environment variables
SCAN_RESULTS_TABLE = os.environ.get('SCAN_RESULTS_TABLE')
VULNERABILITY_INVENTORY_TABLE = os.environ.get('VULNERABILITY_INVENTORY_TABLE')


def lambda_handler(event, context):
    """
    Main Lambda handler - runs on schedule to aggregate vulnerability data
    """
    logger.info("Starting vulnerability aggregation")
    
    try:
        # Aggregate scan results
        scan_summary = aggregate_scan_results()
        
        # Aggregate vulnerability inventory
        vuln_summary = aggregate_vulnerability_inventory()
        
        # Generate report
        report = generate_report(scan_summary, vuln_summary)
        
        logger.info(f"Aggregation complete: {json.dumps(report, default=str)}")
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Vulnerability aggregation completed',
                'summary': report
            }, default=str)
        }
    
    except Exception as e:
        logger.error(f"Error during aggregation: {str(e)}", exc_info=True)
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }


def aggregate_scan_results():
    """
    Aggregate scan results from DynamoDB
    """
    table = dynamodb.Table(SCAN_RESULTS_TABLE)
    
    # Scan last 24 hours of results
    yesterday = int((datetime.utcnow() - timedelta(days=1)).timestamp())
    
    summary = {
        'total_scans': 0,
        'repositories': set(),
        'images': set(),
        'by_severity': defaultdict(int),
        'by_repository': defaultdict(lambda: defaultdict(int)),
        'recent_scans': []
    }
    
    try:
        # Scan table (in production, use GSI for better performance)
        response = table.scan()
        items = response.get('Items', [])
        
        # Handle pagination
        while 'LastEvaluatedKey' in response:
            response = table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])
            items.extend(response.get('Items', []))
        
        for item in items:
            summary['total_scans'] += 1
            
            repo = item.get('repository_name', 'unknown')
            summary['repositories'].add(repo)
            summary['images'].add(item.get('image_digest', 'unknown'))
            
            # Aggregate vulnerabilities by severity
            vuln_counts = item.get('vulnerability_counts', {})
            for severity, count in vuln_counts.items():
                summary['by_severity'][severity] += int(count) if count else 0
                summary['by_repository'][repo][severity] += int(count) if count else 0
            
            # Keep recent scans
            if item.get('scan_timestamp', 0) > yesterday:
                summary['recent_scans'].append({
                    'repository': repo,
                    'tags': item.get('image_tags', []),
                    'timestamp': item.get('scan_completed_at', ''),
                    'vulnerabilities': vuln_counts
                })
        
        # Convert sets to lists for JSON serialization
        summary['repositories'] = list(summary['repositories'])
        summary['images'] = list(summary['images'])
        summary['by_severity'] = dict(summary['by_severity'])
        summary['by_repository'] = {k: dict(v) for k, v in summary['by_repository'].items()}
        
        # Sort recent scans
        summary['recent_scans'].sort(key=lambda x: x['timestamp'], reverse=True)
        summary['recent_scans'] = summary['recent_scans'][:20]  # Limit to 20 most recent
        
        logger.info(f"Aggregated {summary['total_scans']} scan results")
        
        return summary
    
    except ClientError as e:
        logger.error(f"DynamoDB error: {str(e)}", exc_info=True)
        raise


def aggregate_vulnerability_inventory():
    """
    Aggregate unique vulnerabilities across all images
    """
    table = dynamodb.Table(VULNERABILITY_INVENTORY_TABLE)
    
    summary = {
        'total_unique_cves': 0,
        'by_severity': defaultdict(int),
        'top_cves': [],
        'packages_affected': set()
    }
    
    try:
        response = table.scan()
        items = response.get('Items', [])
        
        # Handle pagination
        while 'LastEvaluatedKey' in response:
            response = table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])
            items.extend(response.get('Items', []))
        
        # Process each CVE
        cve_details = []
        
        for item in items:
            summary['total_unique_cves'] += 1
            
            severity = item.get('severity', 'UNKNOWN')
            summary['by_severity'][severity] += 1
            
            package_name = item.get('package_name', 'unknown')
            summary['packages_affected'].add(package_name)
            
            cve_details.append({
                'cve_id': item.get('cve_id', ''),
                'severity': severity,
                'package': package_name,
                'description': item.get('description', '')[:200],  # Truncate
                'last_detected': item.get('last_detected', '')
            })
        
        # Sort by severity and get top CVEs
        severity_order = {'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3, 'INFORMATIONAL': 4, 'UNKNOWN': 5}
        cve_details.sort(key=lambda x: (severity_order.get(x['severity'], 99), x['cve_id']))
        
        summary['top_cves'] = cve_details[:50]  # Top 50 most severe
        summary['packages_affected'] = list(summary['packages_affected'])
        summary['by_severity'] = dict(summary['by_severity'])
        
        logger.info(f"Found {summary['total_unique_cves']} unique CVEs")
        
        return summary
    
    except ClientError as e:
        logger.error(f"DynamoDB error: {str(e)}", exc_info=True)
        raise


def generate_report(scan_summary, vuln_summary):
    """
    Generate comprehensive vulnerability report
    """
    report = {
        'report_generated': datetime.utcnow().isoformat(),
        'summary': {
            'total_scans': scan_summary['total_scans'],
            'total_repositories': len(scan_summary['repositories']),
            'total_images': len(scan_summary['images']),
            'total_unique_cves': vuln_summary['total_unique_cves'],
            'total_packages_affected': len(vuln_summary['packages_affected'])
        },
        'vulnerabilities_by_severity': {
            'scans': scan_summary['by_severity'],
            'unique_cves': vuln_summary['by_severity']
        },
        'repositories': scan_summary['repositories'],
        'repository_breakdown': scan_summary['by_repository'],
        'recent_scans': scan_summary['recent_scans'],
        'top_vulnerabilities': vuln_summary['top_cves'],
        'risk_score': calculate_risk_score(scan_summary, vuln_summary)
    }
    
    return report


def calculate_risk_score(scan_summary, vuln_summary):
    """
    Calculate overall risk score (0-100)
    Based on severity counts and unique CVEs
    """
    score = 0
    
    # Weight by severity
    weights = {
        'CRITICAL': 10,
        'HIGH': 5,
        'MEDIUM': 2,
        'LOW': 1,
        'INFORMATIONAL': 0.5
    }
    
    for severity, count in scan_summary['by_severity'].items():
        score += count * weights.get(severity, 0)
    
    # Normalize to 0-100 scale (arbitrary scaling)
    normalized_score = min(100, score / 10)
    
    return {
        'raw_score': float(score),
        'normalized_score': round(float(normalized_score), 2),
        'risk_level': get_risk_level(normalized_score)
    }


def get_risk_level(score):
    """
    Get risk level based on score
    """
    if score >= 80:
        return 'CRITICAL'
    elif score >= 60:
        return 'HIGH'
    elif score >= 40:
        return 'MEDIUM'
    elif score >= 20:
        return 'LOW'
    else:
        return 'MINIMAL'
